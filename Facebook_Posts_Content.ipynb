{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXj-KBn5gI3j"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPuXVtb4fzaY",
        "outputId": "fd7718b5-5417-4abf-bd4c-80ac97cfa38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-colab-selenium in /usr/local/lib/python3.10/dist-packages (1.0.14)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from google-colab-selenium) (4.23.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->google-colab-selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install google-colab-selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go342-QDf86Q"
      },
      "outputs": [],
      "source": [
        "import google_colab_selenium as gs\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "import re\n",
        "import pandas as pd\n",
        "from lxml import etree\n",
        "#import matplotlib.pyplot as plt\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from time import sleep\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import math\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import json\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCVAi5vGf_Tw",
        "outputId": "6e67fd6f-9bb7-4252-fe4c-7fe7f293ece9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.17).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " google-chrome-stable : Depends: libvulkan1 but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "--2024-08-16 13:36:22--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 185.125.190.81, 185.125.190.83, 91.189.91.82, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|185.125.190.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb.1’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-16 13:36:22 (319 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb.1’ saved [3708/3708]\n",
            "\n",
            "(Reading database ... 123712 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) over (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-08-16 13:36:23--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 142.251.2.93, 142.251.2.190, 142.251.2.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|142.251.2.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109455748 (104M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.1’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 104.38M  90.5MB/s    in 1.2s    \n",
            "\n",
            "2024-08-16 13:36:24 (90.5 MB/s) - ‘google-chrome-stable_current_amd64.deb.1’ saved [109455748/109455748]\n",
            "\n",
            "(Reading database ... 123712 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (127.0.6533.119-1) over (127.0.6533.119-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-08-16 13:36:51--  https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.250.141.207, 74.125.137.207, 142.250.101.207, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘/tmp/chromedriver_linux64.zip’ not modified on server. Omitting download.\n",
            "\n",
            "Archive:  /tmp/chromedriver_linux64.zip\n",
            "  inflating: /tmp/chromedriver       \n",
            "  inflating: /tmp/LICENSE.chromedriver  \n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.23.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up for running selenium in Google Colab\n",
        "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9vbNcUagFWg",
        "outputId": "9b6b2460-98f9-460d-b7d5-fe175c35770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.10/dist-packages (0.6.4)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromedriver-autoinstaller\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "\n",
        "# setup chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument(\"--lang=en\")\n",
        "\n",
        "# set path to chromedriver as per your configuration\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# set the target URL\n",
        "url = \"put-url-here-to-scrape\"\n",
        "\n",
        "# set up the webdriver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGXlZ4mugQG1"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGeJcCNzaIVO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3e6qRWMgl1X"
      },
      "outputs": [],
      "source": [
        "def login(driver):\n",
        "  driver.get('https://www.facebook.com/login/')\n",
        "\n",
        "  driver.find_element(By.NAME, \"email\").send_keys('abdo.barca.boy@hotmail.com')\n",
        "  print (\"Email Id entered\")\n",
        "  sleep(1)\n",
        "\n",
        "  driver.find_element(By.NAME, \"pass\").send_keys('modmengame222')\n",
        "  print (\"Password entered\")\n",
        "\n",
        "  driver.find_element(By.NAME,\"login\").click()\n",
        "\n",
        "def screenshot(driver):\n",
        "  driver.get_screenshot_as_file('screen.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39Eo5_jNgHqX"
      },
      "outputs": [],
      "source": [
        "def get_head_body(driver):\n",
        "    '''\n",
        "    inputs:\n",
        "        driver(webdriver): The Web Driver will be used\n",
        "\n",
        "    returns:\n",
        "        head(etreeELement): Head Etree element\n",
        "        body(etreeELement): Body Etree element\n",
        "    '''\n",
        "    # Getting Head Element\n",
        "    head=driver.find_element(By.TAG_NAME,'head')\n",
        "    headElemnt = head.get_attribute('outerHTML') #gives exact HTML content of the element\n",
        "    headHtml = BeautifulSoup(headElemnt,'html') # Convert the string content into html elements\n",
        "    headEtree= etree.HTML(str(headHtml)) # Convert the Element to etree elemnt (LXML)\n",
        "\n",
        "    # Getting Body Elemnt\n",
        "    body=driver.find_element(By.TAG_NAME,'body')\n",
        "    bodyElemnt = body.get_attribute('outerHTML') #gives exact HTML content of the element\n",
        "    bodyHtml = BeautifulSoup(bodyElemnt,'html') # Convert the string content into html elements\n",
        "    bodyEtree = etree.HTML(str(bodyHtml)) # Convert the Element to etree elemnt (LXML)\n",
        "\n",
        "    return headEtree , bodyEtree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVkFQZAxu6Zl"
      },
      "outputs": [],
      "source": [
        "def find_text(path):\n",
        "  element = driver.find_element(By.XPATH,path)\n",
        "  html_content = element.get_attribute('innerHTML')\n",
        "  s = BeautifulSoup(html_content, 'html.parser')\n",
        "  text_elements = s.find_all(text=True)\n",
        "  cleaned_texts=[]\n",
        "  for t in text_elements:\n",
        "    cleaned_texts.append(re.sub(r\"[^\\w\\s]\", \"\", t))\n",
        "\n",
        "  return cleaned_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZQQwW1L0AB7"
      },
      "outputs": [],
      "source": [
        "def contains_number(text):\n",
        "  text=str(text)\n",
        "  return bool(re.search(r'\\d', text, flags=re.IGNORECASE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8WW4fjk00vu"
      },
      "outputs": [],
      "source": [
        "IMG_BASE_PATH='/html/body/div[1]/div/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div/div/div[2]/div/div/div/div/div/div/div/div/div'\n",
        "\n",
        "def content_type(body):\n",
        "  m1=None\n",
        "  m2=None\n",
        "  try:\n",
        "    m1=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[3]/div[2]/div[1]/div/div/div/div[1]/a/div[1]/div[1]/div/img')\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    m2=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[3]/div[2]/div[1]/a/div[1]/div/div/div/img')\n",
        "  except:\n",
        "    pass\n",
        "  if len(m1) >0 or len(m2)>0:\n",
        "    return 'img'\n",
        "  else:\n",
        "    return 'other'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9mHRgu8gOaO"
      },
      "outputs": [],
      "source": [
        "def get_post_elements(driver,url):\n",
        "    '''\n",
        "     Get posts elemnts (comments, likes, contetn , creation_date & text)\n",
        "\n",
        "    inputs:\n",
        "        utl(str): URL of post page\n",
        "\n",
        "    '''\n",
        "    driver.get(url) # Open post page\n",
        "    sleep(0.5)\n",
        "    #driver.execute_scrpt(\"window.scrollTo(0, document.body.scrollHeight);\") # executing Script that scroll the page\n",
        "    head, body= get_head_body(driver) # Get Head & body HTML contents\n",
        "\n",
        "    content='Other'\n",
        "\n",
        "    if url.split('/')[4]=='videos':\n",
        "        # Get text elemnt\n",
        "        text=find_text('/html/body/div[1]/div/div/div[1]/div/div[3]/div/div/div[1]/div[2]/div/div/div/div[1]/div/div/div[2]/div[1]/div[5]/div/span')\n",
        "        # Get likes elemnt\n",
        "        likes=body.xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div/div/div[1]/div[2]/div/div/div/div[1]/div/div/div[1]/div[2]/div[2]/div/div/div[2]/div/div[1]/div/span/span/span/text()[1]')\n",
        "        if not contains_number(likes):\n",
        "          likes=body.xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div/div/div[1]/div[2]/div/div/div/div[1]/div/div/div[1]/div[2]/div[2]/div/div/div[2]/div/div[1]/div/span/span/span/text()[2]')\n",
        "        # Get comments elemnt\n",
        "        comments=body.xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div/div/div[1]/div[2]/div/div/div/div[1]/div/div/div[1]/div[2]/div[2]/div/div/div[2]/div/div[3]/span/a/span')[0].text\n",
        "        # Get Post creation time\n",
        "        # Get content element\n",
        "        content= 'vid'\n",
        "\n",
        "    else:\n",
        "        # Get text elemnt\n",
        "        text=find_text(f'{IMG_BASE_PATH}/div[*]/div/div/div[3]/div[1]/div/div/div/span')\n",
        "\n",
        "        # Get likes elemnt\n",
        "        likes=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span/text()[1]')\n",
        "        if not contains_number(likes):\n",
        "          likes=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span/text()[2]')\n",
        "        # Get content element\n",
        "        content=content_type(body)\n",
        "\n",
        "        try: # comments have some bugs, so some times they break the code\n",
        "        # Get comments elemnt\n",
        "            comments=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[2]/div[2]/span/a/div/div[1]/span')\n",
        "\n",
        "\n",
        "            comments=comments[0].text\n",
        "        except:\n",
        "          try:\n",
        "            sleep(0.5)\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # executing Script that scroll the page\n",
        "            head, body= get_head_body(driver) # Get Head & body HTML contents\n",
        "            comments=body.xpath(f'{IMG_BASE_PATH}/div[13]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[2]/div[2]/span/a/div/div[1]/span')\n",
        "\n",
        "            comments=comments[0].text\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "    time_script=find_creation_time_script(body)\n",
        "    time_unix=find_creation_time(time_script)\n",
        "    date= convert_unix_time(time_unix)\n",
        "    full_text=\"\"\n",
        "    for line in text:\n",
        "        full_text+=line\n",
        "    return {'text':full_text,'content':content,'date':date,'comments':comments,'likes':likes,'link':url}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXvIGPPki0z6"
      },
      "outputs": [],
      "source": [
        "def find_creation_time_script(body):\n",
        "  for i in range(400):\n",
        "    x=body.xpath(f'/html/body/script[{i}]')\n",
        "\n",
        "    try:\n",
        "      if \"creation_time\" in x[0].text:\n",
        "        return x[0].text\n",
        "    except:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s697hp7EgfUn"
      },
      "outputs": [],
      "source": [
        "def find_creation_time(data):\n",
        "  return int(data.split(\"creation_time\")[1].split('\\\"')[1].replace(':','').replace(',',''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD0zIwGY0Rsw"
      },
      "outputs": [],
      "source": [
        "def convert_unix_time(date):\n",
        "  dt = datetime.datetime.fromtimestamp(date)\n",
        "  # Format the datetime as a string\n",
        "  formatted_date = dt.strftime(\"%Y-%m-%d\")\n",
        "  return formatted_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch8etXlMjqd-"
      },
      "outputs": [],
      "source": [
        "def convert_seconds(seconds):\n",
        "  \"\"\"Converts seconds to hours, minutes, and seconds.\"\"\"\n",
        "  hours = int(seconds // 3600)\n",
        "  minutes = int((seconds % 3600) // 60)\n",
        "  seconds = int(seconds % 60)\n",
        "  return f\"{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1j3xUWrgt9A"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxklx1SKgwCy",
        "outputId": "975056a4-37f9-4205-ceb6-42e66ba07fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email Id entered\n",
            "Password entered\n"
          ]
        }
      ],
      "source": [
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "login(driver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "707C8uV3g1Bo"
      },
      "outputs": [],
      "source": [
        "screenshot(driver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cst86svZiXT3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Khalilalbalush_Links (2).csv',index_col=False)\n",
        "# df_done1=pd.read_csv('/content/Talha_Data (1).csv',index_col=False)\n",
        "# df_done2=pd.read_csv('/content/Awwad_Data2.csv',index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHtRdcuWYP-g",
        "outputId": "ee7c782b-2ba3-4a03-d68a-efc0dba84cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1296"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "links=list(df['link'])\n",
        "links_set=set()\n",
        "# links_set = set(list(df_done1['link']))\n",
        "# links_set.update(list(list(df_done2['link'])))\n",
        "dataset=pd.DataFrame(columns=['text','content','date','comments','likes','link'])\n",
        "# print(len(links_set))\n",
        "remaining_links = list(set(links) - links_set)\n",
        "len(remaining_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCjmHPolY5oK",
        "outputId": "7344f28f-3f25-4105-fdc0-21a99d7772cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress:  454 | remaining:  842                  errors:  7\n",
            "Time left:  1 hours, 49 minutes, 13 seconds\n"
          ]
        }
      ],
      "source": [
        "errors=0\n",
        "done=0\n",
        "full_time=0\n",
        "expeced_time =0\n",
        "remaining=len(links)-len(links_set)-errors\n",
        "for i in remaining_links:\n",
        "  clear_output()\n",
        "\n",
        "  print('Progress: ' , done, '| remaining: ',remaining , '                 errors: ' , errors)\n",
        "  print('Time left: ' ,convert_seconds(expeced_time))\n",
        "  try:\n",
        "    if i not in links_set:\n",
        "      start_time = time.time()\n",
        "      row=get_post_elements(driver,i)\n",
        "      end_time = time.time()\n",
        "      dataset.loc[len(dataset)]=row\n",
        "      links_set.add(i)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    errors+=1\n",
        "\n",
        "  if done % 10 == 0:\n",
        "     dataset.to_csv(f'Khalil_Data.csv', index=False)\n",
        "  remaining-=1\n",
        "  done+=1\n",
        "  full_time+=(end_time - start_time)\n",
        "  expeced_time = (full_time/done) * remaining\n",
        "dataset.to_csv(f'Khalil_Data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dc-28xpaQ1a",
        "outputId": "94dc0a4a-685a-4d05-8b6e-948ce2fd4910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected time:  0 hours, 0 minutes, 33 seconds\n",
            "expected time:  0 hours, 0 minutes, 19 seconds\n",
            "expected time:  0 hours, 0 minutes, 11 seconds\n",
            "expected time:  0 hours, 0 minutes, 5 seconds\n",
            "expected time:  0 hours, 0 minutes, 0 seconds\n"
          ]
        }
      ],
      "source": [
        " full_time=0\n",
        "expeced_time =0\n",
        "remaining=5\n",
        "for i in range(5):\n",
        "  start_time = time.time()\n",
        "  driver.get('https://www.facebook.com/DerradjiHafid/posts/pfbid0jjiEKx7PXtjjS8ETsK7G4JQJwU8xqaigmTPwYbuSQJcwd7uLNfFx8sXp8HeK1TCql?__cft__[0]=AZUilD2rNVR0_Jid6h7k8X6x3t3lsRG5p8beAasJ87382G6zrC_VQ-GrlOWyiM-lM0IngXUpShdEwgEx1pCbK1Kj6opLzLKr1YQRPvDdORG3ndsRDfNS541p0ynmCagFPizn8_N_ZaXbQEMyk8cXRFKG9LM8sJWka7MDtVT6ex51OiaoAPbOn2QcYSvV1BKnXiOvcbAAVPw4Xq257WF_bqic&__tn__=%2CO%2CP-R')\n",
        "  screenshot(driver)\n",
        "  end_time = time.time()\n",
        "  full_time+=(end_time - start_time)\n",
        "  remaining-=1\n",
        "  expeced_time = (full_time/(i+1)) * remaining\n",
        "  print('expected time: ', convert_seconds(expeced_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA1NIzQtaUVR"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/Khalil_Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96vt1NfKwmNS",
        "outputId": "8bd81242-9208-4fdb-f6ec-ee970598bb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3037\n"
          ]
        }
      ],
      "source": [
        "df1=pd.read_csv('/content/Awwad_Data1.csv',index_col=False)\n",
        "df2=pd.read_csv('/content/Awwad_Data2.csv',index_col=False)\n",
        "df3=pd.read_csv('/content/Awwad_Data3.csv',index_col=False)\n",
        "print(df1.shape[0]+df2.shape[0]+df3.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EakwqAVYza7x",
        "outputId": "51fab930-2b96-4170-9117-d7fc018478c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3037, 6)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4=pd.concat([df1,df2,df3],axis=0)\n",
        "df4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V45xlbGiD8I"
      },
      "outputs": [],
      "source": [
        "df4.to_csv('Awwad_Data.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w5NqiYUinpD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qXj-KBn5gI3j",
        "EGXlZ4mugQG1"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}